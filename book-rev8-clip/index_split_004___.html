<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
  <head>
    <title>xv6 - DRAFT as of September 3, 2014</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<p class="block_12" id="calibre_pb_7">Chapter 2</p>
	<h1 id="id_Toc460887576" class="block_13">Page tables</h1>
	<p class="block_40">Page tables are the mechanism through which the operating system controls what memory addresses mean. They allow xv6 to multiplex the address spaces of different processes onto a single physical memory, and to protect the memories of different processes. The level of indirection provided by page tables is also a source for many neat tricks. xv6 uses page tables primarily to multiplex address spaces and to protect memory. It also uses a few simple page-table tricks: mapping the same memory (the kernel) in several address spaces, mapping the same memory more than once in one address space (each user page is also mapped into the kernel’s physical view of memory), and guarding a user stack with an unmapped page. The rest of this chapter explains the page tables that the x86 hardware provides and how xv6 uses them.</p>
	<h3 class="block_17">Paging hardware</h3>
	<p class="block_11">As a reminder, x86 instructions (both user and kernel) manipulate virtual addresses. The machine’s RAM, or physical memory, is indexed with physical addresses. The x86 page table hardware connects these two kinds of addresses, by mapping each virtual address to a physical address.</p>
	<p class="block_15">An x86 page table is logically an array of 2^20 (1,048,576) <span class="text_3">page table entries (PTEs)</span>. Each PTE contains a 20-bit physical page number (PPN) and some flags. The paging hardware translates a virtual address by using its top 20 bits to index into the page table to find a PTE, and replacing the address’s top 20 bits with the PPN in the PTE. The paging hardware copies the low 12 bits unchanged from the virtual to the translated physical address. Thus a page table gives the operating system control over virtual-to-physical address translations at the granularity of aligned chunks of 4096 (2^12) bytes. Such a chunk is called a <span class="text_3">page</span>.</p>
	<p class="block_15">As shown in Figure 2-1, the actual translation happens in two steps. A page table is stored in physical memory as a two-level tree. The root of the tree is a 4096-byte <span class="text_3">page directory </span>that contains 1024 PTE-like references to <span class="text_3">page table pages</span>. Each page table page is an array of 1024 32-bit PTEs. The paging hardware uses the top 10 bits of a virtual address to select a page directory entry. If the page directory entry is present, the paging hardware uses the next 10 bits of the virtual address to select a PTE from the page table page that the page directory entry refers to. If either the page directory entry or the PTE is not present, the paging hardware raises a fault. This two-level structure allows a page table to omit entire page table pages in the common case in which large ranges of virtual addresses have no mappings.</p>
	<p class="block_15">Each PTE contains flag bits that tell the paging hardware how the associated virtual address is allowed to be used. <span class="text_3">PTE_P </span>indicates whether the PTE is present: if it is not set, a reference to the page causes a fault (i.e. is not allowed). <span class="text_3">PTE_W </span>controls</p>
	<p class="block_93"><img alt="Image" src="images/image.png" class="calibre4"/></p>
	<p class="block_33"><b class="calibre2">Figure 2-1</b>. x86 page table hardware.</p>
	<p class="block_94"><span class="text_7">whether instructions are allowed to issue writes to the page; if not set, only reads and instruction fetches are allowed. </span><span class="text_8">PTE_U </span><span class="text_7">controls whether user programs are allowed to use the page; if clear, only the kernel is allowed to use the page. Figure 2-1 shows how it all works. The flags and all other page hardware related structures are defined in </span><span class="text_8">mmu.h </span><span class="text_6">(0700)</span><span class="text_7">.</span></p>
	<p class="block_82"><span class="text_5"></span><span class="text_4">A few notes about terms. Physical memory refers to storage cells in DRAM. A byte of physical memory has an address, called a physical address. Instructions use only virtual addresses, which the paging hardware translates to physical addresses, and then sends to the DRAM hardware to read or write storage. At this level of discussion there is no such thing as virtual memory, only virtual addresses.</span></p>
	<h3 class="block_56">Process address space</h3>
	<p class="block_18"><span class="text_7">The page table created by </span><span class="text_8">entry </span><span class="text_7">has enough mappings to allow the kernel’s C code to start running. However, </span><span class="text_8">main </span><span class="text_7">immediately changes to a new page table by calling </span><span class="text_8">kvmalloc </span><span class="text_6">(1857)</span><span class="text_7">, because kernel has a more elaborate plan for describing process address spaces.</span></p>
	<p class="block_18"><span class="text_7">Each process has a separate page table, and xv6 tells the page table hardware to switch page tables when xv6 switches between processes. As shown in Figure 2-2, a process’s user memory starts at virtual address zero and can grow up to </span><span class="text_8">KERNBASE</span><span class="text_7">, allowing a process to address up to 2 GB of memory. The file </span><span class="text_8">memlayout.h </span><span class="text_6">(0200) </span><span class="text_7">declares the constants for xv6’s memory layout, and macros to convert virtual to physical addresses.</span></p>
	<p class="block_15">When a process asks xv6 for more memory, xv6 first finds free physical pages to provide the storage, and then adds PTEs to the process’s page table that point to the new physical pages. xv6 sets the <span class="text_3">PTE_U</span>, <span class="text_3">PTE_W</span>, and <span class="text_3">PTE_P </span>flags in these PTEs. Most processes do not use the entire user address space; xv6 leaves <span class="text_3">PTE_P </span>clear in unused PTEs. Different processes’ page tables translate user addresses to different pages of physical memory, so that each process has private user memory.</p>
	<p class="block_18"><span class="text_6"></span><span class="text_7">Xv6 includes all mappings needed for the kernel to run in every process’s page table; these mappings all appear above </span><span class="text_8">KERNBASE</span><span class="text_7">. It maps virtual addresses </span><span class="text_8">KERNBASE:KERNBASE+PHYSTOP </span><span class="text_7">to </span><span class="text_8">0:PHYSTOP</span><span class="text_7">. One reason for this mapping is so that the kernel can use its own instructions and data. Another reason is that the kernel sometimes needs to be able to write a given page of physical memory, for example when creating page table pages; having every physical page appear at a predictable virtual address makes this convenient. A defect of this arrangement is that xv6 cannot make use of more than 2 GB of physical memory. Some devices that use memory-mapped I/O appear at physical addresses starting at </span><span class="text_8">0xFE000000</span><span class="text_7">, so xv6 page tables including a direct mapping for them. Xv6 does not set the </span><span class="text_8">PTE_U </span><span class="text_7">flag in the PTEs above </span><span class="text_8">KERNBASE</span><span class="text_7">, so only the kernel can use them.</span></p>
	<p class="block_95">0</p>
	<p class="block_95">User<span class="text_23"> </span>data</p>
	<p class="block_95">User<span class="text_23"> </span>text</p>
	<p class="block_95">User<span class="text_23"> </span>stack</p>
	<p class="block_95">Program<span class="text_23"> </span>data<span class="text_24"> </span>&amp;<span class="text_23"> </span>heap</p>
	<p class="block_95">+<span class="text_23"> </span>0x100000</p>
	<p class="block_95">Kernel<span class="text_23"> </span>text</p>
	<p class="block_95">end</p>
	<p class="block_95">KERNBASE</p>
	<p class="block_95">Kernel<span class="text_23"> </span>data</p>
	<p class="block_95"><span class="text_23"> </span>Gig</p>
	<p class="block_95">4</p>
	<p class="block_95">0</p>
	<p class="block_96">RW--</p>
	<p class="block_96">RW-</p>
	<p class="block_95">RWU</p>
	<p class="block_95">Device<span class="text_23"> </span>memory</p>
	<p class="block_95">xFE</p>
	<p class="block_95">0</p>
	<p class="block_95">000000</p>
	<p class="block_95">Free<span class="text_23"> </span>memory</p>
	<p class="block_96">RW-</p>
	<p class="block_95">R--</p>
	<p class="block_97">Virtual</p>
	<p class="block_95">0x100000</p>
	<p class="block_95">PHYSTOP</p>
	<p class="block_95">Devices</p>
	<p class="block_95">Extended<span class="text_23"> </span>memory</p>
	<p class="block_95">K</p>
	<p class="block_95">640</p>
	<p class="block_95">I/O<span class="text_23"> </span>space</p>
	<p class="block_95">Base<span class="text_23"> </span>memory</p>
	<p class="block_97">Physical</p>
	<p class="block_95">4</p>
	<p class="block_95"><span class="text_23"> </span>Gig</p>
	<p class="block_95">RWU</p>
	<p class="block_95">RWU</p>
	<p class="block_95">PAGESIZE</p>
	<p class="block_96">RW-</p>
	<p class="block_20"><b class="calibre2">Figure</b><span class="text_9"> </span><b class="calibre2">2-2</b></p>
	<p class="block_20">.<span class="text_19"> </span>Layout<span class="text_11"> </span>of<span class="text_20"> </span>a<span class="text_11"> </span>virtual<span class="text_11"> </span>address<span class="text_11"> </span>space<span class="text_11"> </span>and<span class="text_11"> </span>the<span class="text_11"> </span>physical<span class="text_11"> </span>address<span class="text_11"> </span>space.</p>
	<p class="block_95">0</p>
	<p class="block_95">User<span class="text_23"> </span>data</p>
	<p class="block_95">User<span class="text_23"> </span>text</p>
	<p class="block_95">User<span class="text_23"> </span>stack</p>
	<p class="block_95">Program<span class="text_23"> </span>data<span class="text_24"> </span>&amp;<span class="text_23"> </span>heap</p>
	<p class="block_95">+<span class="text_23"> </span>0x100000</p>
	<p class="block_95">Kernel<span class="text_23"> </span>text</p>
	<p class="block_95">end</p>
	<p class="block_95">KERNBASE</p>
	<p class="block_95">Kernel<span class="text_23"> </span>data</p>
	<p class="block_95"><span class="text_23"> </span>Gig</p>
	<p class="block_95">4</p>
	<p class="block_95">0</p>
	<p class="block_96">RW--</p>
	<p class="block_96">RW-</p>
	<p class="block_95">RWU</p>
	<p class="block_95">Device<span class="text_23"> </span>memory</p>
	<p class="block_95">xFE</p>
	<p class="block_95">0</p>
	<p class="block_95">000000</p>
	<p class="block_95">Free<span class="text_23"> </span>memory</p>
	<p class="block_96">RW-</p>
	<p class="block_95">R--</p>
	<p class="block_97">Virtual</p>
	<p class="block_95">0x100000</p>
	<p class="block_95">PHYSTOP</p>
	<p class="block_95">Devices</p>
	<p class="block_95">Extended<span class="text_23"> </span>memory</p>
	<p class="block_95">K</p>
	<p class="block_95">640</p>
	<p class="block_95">I/O<span class="text_23"> </span>space</p>
	<p class="block_95">Base<span class="text_23"> </span>memory</p>
	<p class="block_97">Physical</p>
	<p class="block_95">4</p>
	<p class="block_95"><span class="text_23"> </span>Gig</p>
	<p class="block_95">RWU</p>
	<p class="block_95">RWU</p>
	<p class="block_95">PAGESIZE</p>
	<p class="block_96">RW-</p>
	<p class="block_20"><b class="calibre2">Figure</b><span class="text_9"> </span><b class="calibre2">2-2</b></p>
	<p class="block_20">.<span class="text_19"> </span>Layout<span class="text_11"> </span>of<span class="text_20"> </span>a<span class="text_11"> </span>virtual<span class="text_11"> </span>address<span class="text_11"> </span>space<span class="text_11"> </span>and<span class="text_11"> </span>the<span class="text_11"> </span>physical<span class="text_11"> </span>address<span class="text_11"> </span>space.</p>
	<p class="block_98">Having every process’s page table contain mappings for both user memory and</p>
	<p class="block_11">the entire kernel is convenient when switching from user code to kernel code during system calls and interrupts: such switches do not require page table switches. For the most part the kernel does not have its own page table; it is almost always borrowing some process’s page table.</p>
	<p class="block_80">To review, xv6 ensures that each process can only use its own memory, and that each process sees its memory as having contiguous virtual addresses starting at zero. xv6 implements the first by setting the <span class="text_3">PTE_U </span>bit only on PTEs of virtual addresses that refer to the process’s own memory. It implements the second using the ability of page tables to translate successive virtual addresses to whatever physical pages happen to be allocated to the process.</p>
	<h3 class="block_99">Code: creating an address space</h3>
	<p class="block_18"><span class="text_8">main </span><span class="text_7">calls </span><span class="text_8">kvmalloc </span><span class="text_6">(1857) </span><span class="text_7">to create and switch to a page table with the mappings above </span><span class="text_8">KERNBASE </span><span class="text_7">required for the kernel to run. Most of the work happens in </span><span class="text_8">setupkvm </span><span class="text_6">(1837)</span><span class="text_7">. It first allocates a page of memory to hold the page directory. Then it calls </span><span class="text_8">mappages </span><span class="text_7">to install the translations that the kernel needs, which are described in the </span><span class="text_8">kmap </span><span class="text_6">(1828) </span><span class="text_7">array. The translations include the kernel’s instructions and data, physical memory up to </span><span class="text_8">PHYSTOP</span><span class="text_7">, and memory ranges which are actually I/O devices. </span><span class="text_8">setupkvm </span><span class="text_7">does not install any mappings for the user memory; this will happen later.</span></p>
	<p class="block_18"><span class="text_8">mappages </span><span class="text_6">(1779) </span><span class="text_7">installs mappings into a page table for a range of virtual addresses to a corresponding range of physical addresses. It does this separately for each virtual address in the range, at page intervals. For each virtual address to be mapped, </span><span class="text_8">mappages </span><span class="text_7">calls </span><span class="text_8">walkpgdir </span><span class="text_7">to find the address of the PTE for that address. It then initializes the PTE to hold the relevant physical page number, the desired permissions ( </span><span class="text_8">PTE_W </span><span class="text_7">and/or </span><span class="text_8">PTE_U</span><span class="text_7">), and </span><span class="text_8">PTE_P </span><span class="text_7">to mark the PTE as valid </span><span class="text_6">(1791)</span><span class="text_7">.</span></p>
	<p class="block_100"><span class="text_8">walkpgdir </span><span class="text_6">(1754) </span><span class="text_7">mimics the actions of the x86 paging hardware as it looks up the PTE for a virtual address (see Figure 2-1). </span><span class="text_8">walkpgdir </span><span class="text_7">uses the upper 10 bits of the virtual address to find the page directory entry </span><span class="text_6">(1759)</span><span class="text_7">. If the page directory entry isn’t present, then the required page table page hasn’t yet been allocated; if the </span><span class="text_8">alloc </span><span class="text_7">argument is set, </span><span class="text_8">walkpgdir </span><span class="text_7">allocates it and puts its physical address in the page directory. Finally it uses the next 10 bits of the virtual address to find the address of the PTE in the page table page </span><span class="text_6">(1772)</span><span class="text_7">.</span></p>
	<h3 class="block_17">Physical memory allocation</h3>
	<p class="block_14">The kernel needs to allocate and free physical memory at run-time for page tables, process user memory, kernel stacks, and pipe buffers.</p>
	<p class="block_15">xv6 uses the physical memory between the end of the kernel and <span class="text_3">PHYSTOP </span>for run-time allocation. It allocates and frees whole 4096-byte pages at a time. It keeps track of which pages are free by threading a linked list through the pages themselves. Allocation consists of removing a page from the linked list; freeing consists of adding the freed page to the list.</p>
	<p class="block_101">There is a bootstrap problem: all of physical memory must be mapped in order for the allocator to initialize the free list, but creating a page table with those mappings involves allocating page-table pages. xv6 solves this problem by using a separate page allocator during entry, which allocates memory just after the end of the kernel’s data segment. This allocator does not support freeing and is limited by the 4 MB mapping in the <span class="text_3">entrypgdir</span>, but that is sufficient to allocate the first kernel page table.</p>
	<h3 class="block_17">Code: Physical memory allocator</h3>
	<p class="block_18"><span class="text_7">The allocator’s data structure is a </span><span class="text_15">free list </span><span class="text_7">of physical memory pages that are available for allocation. Each free page’s list element is a </span><span class="text_8">struct run </span><span class="text_6">(3014)</span><span class="text_7">. Where does the allocator get the memory to hold that data structure? It store each free page’s </span><span class="text_8">run </span><span class="text_7">structure in the free page itself, since there’s nothing else stored there. The free list is protected by a spin lock </span><span class="text_6">(3018-3022)</span><span class="text_7">. The list and the lock are wrapped in a struct to make clear that the lock protects the fields in the struct. For now, ignore the lock and the calls to </span><span class="text_8">acquire </span><span class="text_7">and </span><span class="text_8">release</span><span class="text_7">; Chapter 4 will examine locking in detail.</span></p>
	<p class="block_18"><span class="text_7">The function </span><span class="text_8">main </span><span class="text_7">calls </span><span class="text_8">kinit1 </span><span class="text_7">and </span><span class="text_8">kinit2 </span><span class="text_7">to initialize the allocator </span><span class="text_6">(3030)</span><span class="text_7">. The reason for having two calls is that for much of </span><span class="text_8">main </span><span class="text_7">one cannot use locks or memory above 4 megabytes. The call to </span><span class="text_8">kinit1 </span><span class="text_7">sets up for lock-less allocation in the first 4 megabytes, and the call to </span><span class="text_8">kinit2 </span><span class="text_7">enables locking and arranges for more memory to be allocatable. </span><span class="text_8">main </span><span class="text_7">ought to determine how much physical memory is available, but this turns out to be difficult on the x86. Instead it assumes that the machine has 240 megabytes (</span><span class="text_8">PHYSTOP</span><span class="text_7">) of physical memory, and uses all the memory between the end of the kernel and </span><span class="text_8">PHYSTOP </span><span class="text_7">as the initial pool of free memory. </span><span class="text_8">kinit1 </span><span class="text_7">and </span><span class="text_8">kinit2 </span><span class="text_7">call </span><span class="text_8">freerange </span><span class="text_7">to add memory to the free list via per-page calls to </span><span class="text_8">kfree</span><span class="text_7">. A PTE can only refer to a physical address that is aligned on a 4096-byte boundary (is a multiple of 4096), so </span><span class="text_8">freerange </span><span class="text_7">uses </span><span class="text_8">PGROUNDUP </span><span class="text_7">to ensure that it frees only aligned physical addresses. The allocator starts with no memory; these calls to </span><span class="text_8">kfree </span><span class="text_7">give it some to manage.</span></p>
	<p class="block_15">The allocator refers to physical pages by their virtual addresses as mapped in high memory, not by their physical addresses, which is why <span class="text_3">kinit </span>uses <span class="text_3">p2v(PHYSTOP) </span>to translate <span class="text_3">PHYSTOP </span>(a physical address) to a virtual address. The allocator sometimes treats addresses as integers in order to perform arithmetic on them (e.g., traversing all pages in <span class="text_3">kinit</span>), and sometimes uses addresses as pointers to read and write memory (e.g., manipulating the <span class="text_3">run </span>structure stored in each page); this dual use of addresses is the main reason that the allocator code is full of C type casts. The other reason is that freeing and allocation inherently change the type of the memory.</p>
	<p class="block_100"><span class="text_7">The function </span><span class="text_8">kfree </span><span class="text_6">(3065) </span><span class="text_7">begins by setting every byte in the memory being freed to the value 1. This will cause code that uses memory after freeing it (uses ‘‘dangling references’’) to read garbage instead of the old valid contents; hopefully that will cause such code to break faster. Then </span><span class="text_8">kfree </span><span class="text_7">casts </span><span class="text_8">v </span><span class="text_7">to a pointer to </span><span class="text_8">struct run</span><span class="text_7">, records the old start of the free list in </span><span class="text_8">r-&gt;next</span><span class="text_7">, and sets the free list equal to </span><span class="text_8">r</span><span class="text_7">. </span><span class="text_8">kalloc </span><span class="text_7">removes and returns the first element in the free list.</span></p>
	<h3 class="block_17">User part of an address space</h3>
	<p class="block_98">Figure 2-3 shows the layout of the user memory of an executing process in xv6.</p>
	<p class="block_63">The heap is above the stack so that it can expand (with <span class="text_3">sbrk</span>). The stack is a single page, and is shown with the initial contents as created by exec. Strings containing the command-line arguments, as well as an array of pointers to them, are at the very top of the stack. Just under that are values that allow a program to start at <span class="text_3">main </span>as if the function call <span class="text_3">main(argc, argv) </span>had just started. To guard a stack growing off the stack page, xv6 places a guard page right below the stack. The guard page is not mapped and so if the stack runs off the stack page, the hardware will generate an exception because it cannot translate the faulting address.</p>
	<h3 class="block_17">Code: exec</h3>
	<p class="block_88"><span class="text_6"></span><span class="text_7">Exec is the system call that creates the user part of an address space. It initializes the user part of an address space from a file stored in the file system. </span><span class="text_8">Exec </span><span class="text_6">(6310) </span><span class="text_7">opens the named binary </span><span class="text_8">path </span><span class="text_7">using </span><span class="text_8">namei </span><span class="text_6">(6321)</span><span class="text_7">, which is explained in Chapter 6. Then, it reads the ELF header. Xv6 applications are described in the widely-used </span><span class="text_8">ELF format</span><span class="text_7">, defined in </span><span class="text_8">elf.h</span><span class="text_7">. An ELF binary consists of an ELF header, </span><span class="text_8">struct elfhdr </span><span class="text_6">(0955)</span><span class="text_7">, followed by a sequence of program section headers, </span><span class="text_8">struct proghdr </span><span class="text_6">(0974)</span><span class="text_7">. Each </span><span class="text_8">proghdr </span><span class="text_7">describes a section of the application that must be loaded into memory; xv6 programs have only one program section header, but other systems might have separate sections for instructions and data.</span></p>
	<p class="block_19">0</p>
	<p class="block_19">KERNBASE</p>
	<p class="block_19">text</p>
	<p class="block_19">data</p>
	<p class="block_19">stack</p>
	<p class="block_19">heap</p>
	<p class="block_19">PAGESIZE</p>
	<p class="block_19">argument<span class="text_16"> </span>0</p>
	<p class="block_19">argument<span class="text_16"> </span>N</p>
	<p class="block_19">0</p>
	<p class="block_19">address<span class="text_16"> </span>of<span class="text_16"> </span>argument<span class="text_16"> </span>0</p>
	<p class="block_19"><span class="text_25">address</span><span class="text_26"> </span><span class="text_25">of</span><span class="text_26"> </span><span class="text_25">argument</span><span class="text_26"> </span><span class="text_25">N</span></p>
	<p class="block_19">address<span class="text_16"> </span>of<span class="text_16"> </span>address<span class="text_16"> </span>of</p>
	<p class="block_19"><span class="text_16"> </span>argument<span class="text_16"> </span>0</p>
	<p class="block_19">xFFFFFFF</p>
	<p class="block_19">0</p>
	<p class="block_19">(</p>
	<p class="block_19">empty</p>
	<p class="block_19">)</p>
	<p class="block_19">argc</p>
	<p class="block_19">...</p>
	<p class="block_19">...</p>
	<p class="block_19">nul-terminated<span class="text_16"> </span>string</p>
	<p class="block_19">argv[argc]</p>
	<p class="block_19">argv[0]</p>
	<p class="block_19">argv<span class="text_16"> </span>argument<span class="text_16"> </span>of<span class="text_16"> </span>main</p>
	<p class="block_19">argc<span class="text_18"> </span>argument<span class="text_16"> </span>of<span class="text_16"> </span>main</p>
	<p class="block_19">return<span class="text_16"> </span>PC<span class="text_16"> </span>for<span class="text_16"> </span>main</p>
	<p class="block_19">guard<span class="text_21"> </span>page</p>
	<p class="block_20"><b class="calibre2">Figure</b><span class="text_9"> </span><b class="calibre2">2-3</b></p>
	<p class="block_20">.<span class="text_19"> </span>Memory<span class="text_11"> </span>layout<span class="text_11"> </span>of<span class="text_20"> </span>a<span class="text_11"> </span>user<span class="text_11"> </span>process<span class="text_11"> </span>with<span class="text_11"> </span>its<span class="text_11"> </span>initial<span class="text_11"> </span>stack.</p>
	<p class="block_19">0</p>
	<p class="block_19">KERNBASE</p>
	<p class="block_19">text</p>
	<p class="block_19">data</p>
	<p class="block_19">stack</p>
	<p class="block_19">heap</p>
	<p class="block_19">PAGESIZE</p>
	<p class="block_19">argument<span class="text_16"> </span>0</p>
	<p class="block_19">argument<span class="text_16"> </span>N</p>
	<p class="block_19">0</p>
	<p class="block_19">address<span class="text_16"> </span>of<span class="text_16"> </span>argument<span class="text_16"> </span>0</p>
	<p class="block_19"><span class="text_25">address</span><span class="text_26"> </span><span class="text_25">of</span><span class="text_26"> </span><span class="text_25">argument</span><span class="text_26"> </span><span class="text_25">N</span></p>
	<p class="block_19">address<span class="text_16"> </span>of<span class="text_16"> </span>address<span class="text_16"> </span>of</p>
	<p class="block_19"><span class="text_16"> </span>argument<span class="text_16"> </span>0</p>
	<p class="block_19">xFFFFFFF</p>
	<p class="block_19">0</p>
	<p class="block_19">(</p>
	<p class="block_19">empty</p>
	<p class="block_19">)</p>
	<p class="block_19">argc</p>
	<p class="block_19">...</p>
	<p class="block_19">...</p>
	<p class="block_19">nul-terminated<span class="text_16"> </span>string</p>
	<p class="block_19">argv[argc]</p>
	<p class="block_19">argv[0]</p>
	<p class="block_19">argv<span class="text_16"> </span>argument<span class="text_16"> </span>of<span class="text_16"> </span>main</p>
	<p class="block_19">argc<span class="text_18"> </span>argument<span class="text_16"> </span>of<span class="text_16"> </span>main</p>
	<p class="block_19">return<span class="text_16"> </span>PC<span class="text_16"> </span>for<span class="text_16"> </span>main</p>
	<p class="block_19">guard<span class="text_21"> </span>page</p>
	<p class="block_20"><b class="calibre2">Figure</b><span class="text_9"> </span><b class="calibre2">2-3</b></p>
	<p class="block_20">.<span class="text_19"> </span>Memory<span class="text_11"> </span>layout<span class="text_11"> </span>of<span class="text_20"> </span>a<span class="text_11"> </span>user<span class="text_11"> </span>process<span class="text_11"> </span>with<span class="text_11"> </span>its<span class="text_11"> </span>initial<span class="text_11"> </span>stack.</p>
	<p class="block_18"><span class="text_7">The first step is a quick check that the file probably contains an ELF binary. An ELF binary starts with the four-byte ‘‘magic number’’ </span><span class="text_8">0x7F</span><span class="text_7">, </span><span class="text_8">’E’</span><span class="text_7">, </span><span class="text_8">’L’</span><span class="text_7">, </span><span class="text_8">’F’</span><span class="text_7">, or </span><span class="text_8">ELF_MAGIC </span><span class="text_6">(0952)</span><span class="text_7">. If the ELF header has the right magic number, </span><span class="text_8">exec </span><span class="text_7">assumes that the binary is well-formed.</span></p>
	<p class="block_18"><span class="text_8">Exec </span><span class="text_7">allocates a new page table with no user mappings with </span><span class="text_8">setupkvm </span><span class="text_6">(6334)</span><span class="text_7">, allocates memory for each ELF segment with </span><span class="text_8">allocuvm </span><span class="text_6">(6346)</span><span class="text_7">, and loads each segment into memory with </span><span class="text_8">loaduvm </span><span class="text_6">(6348)</span><span class="text_7">. </span><span class="text_8">allocuvm </span><span class="text_7">checks that the virtual addresses requested is below </span><span class="text_8">KERNBASE</span><span class="text_7">. </span><span class="text_8">loaduvm </span><span class="text_6">(1918) </span><span class="text_7">uses </span><span class="text_8">walkpgdir </span><span class="text_7">to find the physical address of the allocated memory at which to write each page of the ELF segment, and </span><span class="text_8">readi </span><span class="text_7">to read from the file.</span></p>
	<p class="block_43">The program section header for <span class="text_3">/init</span>, the first user program created with <span class="text_3">exec</span>, looks like this:</p>
	<p class="block_38"># objdump -p _init</p>
	<p class="block_102"><span class="text_6"></span><span class="text_27">_init: <span class="tab">       </span>file format elf32-i386</span></p>
	<p class="block_103">Program Header:</p>
	<p class="block_104">LOAD off <span class="tab">       </span>0x00000054 vaddr 0x00000000 paddr 0x00000000 align 2**2 filesz 0x000008c0 memsz 0x000008cc flags rwx</p>
	<p class="block_15">The program section header’s <span class="text_3">filesz </span>may be less than the <span class="text_3">memsz</span>, indicating that the gap between them should be filled with zeroes (for C global variables) rather than read from the file. For <span class="text_3">/init</span>, <span class="text_3">filesz </span>is 2240 bytes and <span class="text_3">memsz </span>is 2252 bytes, and thus <span class="text_3">allocuvm </span>allocates enough physical memory to hold 2252 bytes, but reads only 2240 bytes from the file <span class="text_3">/init</span>.</p>
	<p class="block_15">Now <span class="text_3">exec </span>allocates and initializes the user stack. It allocates just one stack page. <span class="text_3">Exec </span>copies the argument strings to the top of the stack one at a time, recording the pointers to them in <span class="text_3">ustack</span>. It places a null pointer at the end of what will be the <span class="text_3">argv </span>list passed to <span class="text_3">main</span>. The first three entries in <span class="text_3">ustack </span>are the fake return PC, <span class="text_3">argc</span>, and <span class="text_3">argv </span>pointer.</p>
	<p class="block_15"><span class="text_3">Exec </span>places an inaccessible page just below the stack page, so that programs that try to use more than one page will fault. This inaccessible page also allows <span class="text_3">exec </span>to deal with arguments that are too large; in that situation, the <span class="text_3">copyout </span>function that <span class="text_3">exec </span>uses to copy arguments to the stack will notice that the destination page in not accessible, and will return –1.</p>
	<p class="block_89"><span class="text_7">During the preparation of the new memory image, if </span><span class="text_8">exec </span><span class="text_7">detects an error like an invalid program segment, it jumps to the label </span><span class="text_8">bad</span><span class="text_7">, frees the new image, and returns –1. </span><span class="text_8">Exec </span><span class="text_7">must wait to free the old image until it is sure that the system call will succeed: if the old image is gone, the system call cannot return –1 to it. The only error cases in </span><span class="text_8">exec </span><span class="text_7">happen during the creation of the image. Once the image is complete, </span><span class="text_8">exec </span><span class="text_7">can install the new image </span><span class="text_6">(6394) </span><span class="text_7">and free the old one </span><span class="text_6">(6395)</span><span class="text_7">. Finally, </span><span class="text_8">exec </span><span class="text_7">returns 0.</span></p>
	<h3 class="block_17">Real world</h3>
	<p class="block_15">Like most operating systems, xv6 uses the paging hardware for memory protection and mapping. Most operating systems make far more sophisticated use of paging than xv6; for example, xv6 lacks demand paging from disk, copy-on-write fork, shared memory, lazily-allocated pages, and automatically extending stacks. The x86 supports address translation using segmentation (see Appendix B), but xv6 uses segments only for the common trick of implementing per-cpu variables such as <span class="text_3">proc </span>that are at a fixed address but have different values on different CPUs (see <span class="text_3">seginit</span>). Implementations of per-CPU (or per-thread) storage on non-segment architectures would dedicate a register to holding a pointer to the per-CPU data area, but the x86 has so few general registers that the extra effort required to use segmentation is worthwhile.</p>
	<p class="block_18"><span class="text_7">On machines with lots of memory it might make sense to use the x86’s 4 Mbyte ‘‘super pages.’’ Small pages make sense when physical memory is small, to allow allocation and page-out to disk with fine granularity. For example, if a program uses only 8 Kbyte of memory, giving it a 4 Mbyte physical page is wasteful. Larger pages make sense on machines with lots of RAM, and may reduce overhead for page-table manipulation. Xv6 uses super pages in one place: the initial page table </span><span class="text_6">(1311)</span><span class="text_7">. The array initialization sets two of the 1024 PDEs, at indices zero and 512 (</span><span class="text_8">KERNBASE&gt;&gt;PDXSHIFT</span><span class="text_7">), leaving the other PDEs zero. Xv6 sets the </span><span class="text_8">PTE_PS </span><span class="text_7">bit in these two PDEs to mark them as super pages. The kernel also tells the paging hardware to allow super pages by setting the </span><span class="text_8">CR_PSE </span><span class="text_7">bit (Page Size Extension) in </span><span class="text_8">%cr4.</span></p>
	<p class="block_14">Xv6 should determine the actual RAM configuration, instead of assuming 240 MB. On the x86, there are at least three common algorithms: the first is to probe the physical address space looking for regions that behave like memory, preserving the values written to them; the second is to read the number of kilobytes of memory out of a known 16-bit location in the PC’s non-volatile RAM; and the third is to look in BIOS memory for a memory layout table left as part of the multiprocessor tables. Reading the memory layout table is complicated.</p>
	<p class="block_40">Memory allocation was a hot topic a long time ago, the basic problems being efficient use of limited memory and preparing for unknown future requests; see Knuth. Today people care more about speed than space-efficiency. In addition, a more elaborate kernel would likely allocate many different sizes of small blocks, rather than (as in xv6) just 4096-byte blocks; a real kernel allocator would need to handle small allocations as well as large ones.</p>
	<h3 class="block_17">Exercises</h3>
	<ol class="list_">
	<li class="block_105">Look at real operating systems to see how they size memory.</li>
	<li class="block_106">If xv6 had not used super pages, what would be the right declaration for <span class="text_3">entrypgdir?</span></li>
	<li class="block_107">Modify xv6 so that the pages for the kernel are shared among processes, which reduces memory consumption.</li>
	<li class="block_92">Unix implementations of <span class="text_3">exec </span>traditionally include special handling for shell scripts. If the file to execute begins with the text <span class="text_3">#!</span>, then the first line is taken to be a program to run to interpret the file. For example, if <span class="text_3">exec </span>is called to run <span class="text_3">myprog arg1 </span>and <span class="text_3">myprog</span>’s first line is <span class="text_3">#!/interp</span>, then <span class="text_3">exec </span>runs <span class="text_3">/interp </span>with command line <span class="text_3">/interp myprog arg1</span>. Implement support for this convention in xv6.</li>
</ol>
	<p class="block_77">Chapter 3</p>
	<h1 id="id_Toc460887577" class="block_13">Traps, interrupts, and drivers</h1>
	<p class="block_40">When running a process, a CPU executes the normal processor loop: read an instruction, advance the program counter, execute the instruction, repeat. But there are events on which control from a user program must transferred back to the kernel instead of executing the next instruction. These events include a device signaling that it wants attention, a user program doing something illegal (e.g., references a virtual address for which there is no PTE), or a user program asking the kernel for a service with a system call. There are three main challenges in handling these events: 1) the kernel must arrange that a processor switches from user mode to kernel mode (and back); 2) the kernel and devices must coordinate their parallel activities; and 3) the kernel must understand the interface of the devices well. Addressing these 3 challenges requires detailed understanding of hardware and careful programming, and can result in opaque kernel code. This chapter explains how xv6 addresses these three challenges.</p>
	<h3 class="block_17">Systems calls, exceptions, and interrupts</h3>
	<p class="block_26">With a system call a user program can ask for an operating system service, as we saw at the end of the last chapter. The term <span class="text_3">exception </span>refers to an illegal program action that generates an interrupt. Examples of illegal programs actions include divide by zero, attempt to access memory for a PTE that is not present, and so on. The term <span class="text_3">interrupt </span>refers to a signal generated by a hardware device, indicating that it needs attention of the operating system. For example, a clock chip may generate an interrupt every 100 msec to allow the kernel to implement time sharing. As another example, when the disk has read a block from disk, it generates an interrupt to alert the operating system that the block is ready to be retrieved.</p>
	<p class="block_14">The kernel handles all interrupts, rather than processes handling them, because in most cases only the kernel has the required privilege and state. For example, in order to time-slice among processes in response the clock interrupts, the kernel must be involved, if only to force uncooperative processes to yield the processor.</p>
	<p class="block_14">In all three cases, the operating system design must arrange for the following to happen. The system must save the processor’s registers for future transparent resume. The system must be set up for execution in the kernel. The system must chose a place for the kernel to start executing. The kernel must be able to retrieve information about the event, e.g., system call arguments. It must all be done securely; the system must maintain isolation of user processes and the kernel.</p>
	<p class="block_15">To achieve this goal the operating system must be aware of the details of how the hardware handles system calls, exceptions, and interrupts. In most processors these three events are handled by a single hardware mechanism. For example, on the x86, a program invokes a system call by generating an interrupt using the <span class="text_3">int </span>instruction. Similarly, exceptions generate an interrupt too. Thus, if the operating system has a plan for interrupt handling, then the operating system can handle system calls and exceptions too.</p>
	<p class="block_15">The basic plan is as follows. An interrupts stops the normal processor loop and starts executing a new sequence called an <span class="text_3">interrupt handler</span>. Before starting the interrupt handler, the processor saves its registers, so that the operating system can restore them when it returns from the interrupt. A challenge in the transition to and from the interrupt handler is that the processor should switch from user mode to kernel mode, and back.</p>
	<p class="block_80">A word on terminology: Although the official x86 term is interrupt, xv6 refers to all of these as <span class="text_3">traps</span>, largely because it was the term used by the PDP11/40 and therefore is the conventional Unix term. This chapter uses the terms trap and interrupt interchangeably, but it is important to remember that traps are caused by the current process running on a processor (e.g., the process makes a system call and as a result generates a trap), and interrupts are caused by devices and may not be related to the currently running process. For example, a disk may generate an interrupt when it is done retrieving a block for one process, but at the time of the interrupt some other process may be running. This property of interrupts makes thinking about interrupts more difficult than thinking about traps, because interrupts happen concurrently with other activities. Both rely, however, on the same hardware mechanism to transfer control between user and kernel mode securely, which we will discuss next.</p>
	<h3 class="block_17">X86 protection</h3>
	<p class="block_15">The x86 has 4 protection levels, numbered 0 (most privilege) to 3 (least privilege). In practice, most operating systems use only 2 levels: 0 and 3, which are then called <span class="text_3">kernel mode </span>and <span class="text_3">user mode</span>, respectively. The current privilege level with which the x86 executes instructions is stored in <span class="text_3">%cs </span>register, in the field CPL.</p>
	<p class="block_15">On the x86, interrupt handlers are defined in the interrupt descriptor table (IDT). The IDT has 256 entries, each giving the <span class="text_3">%cs </span>and <span class="text_3">%eip </span>to be used when handling the corresponding interrupt.</p>
	<p class="block_108">To make a system call on the x86, a program invokes the <span class="text_3">int </span><span class="text_14">n </span>instruction, where <span class="text_14">n </span>specifies the index into the IDT. The <span class="text_3">int </span>instruction performs the following steps:</p>
	<div class="calibre5">
	<div class="block_109"><span class="bullet_">• </span><span class="calibre6">Fetch the <span class="text_14">n</span>’th descriptor from the IDT, where <span class="text_14">n </span>is the argument of <span class="text_3">int</span>.</span></div>
	<div class="block_110"><span class="bullet_">• </span><span class="calibre6">Check that CPL in <span class="text_3">%cs </span>is &lt;= DPL, where DPL is the privilege level in the descriptor.</span></div>
	<div class="block_111"><span class="bullet_">• </span><span class="calibre6">Save <span class="text_3">%esp </span>and <span class="text_3">%ss </span>in a CPU-internal registers, but only if the target segment selector’s PL &lt; CPL.</span></div>
	<div class="block_112"><span class="bullet_">• </span><span class="calibre6">Load <span class="text_3">%ss </span>and <span class="text_3">%esp </span>from a task segment descriptor.</span></div>
	<div class="block_113"><span class="bullet_">• </span><span class="calibre6">Push <span class="text_3">%ss.</span></span></div>
</div>
	<p class="block_114"><span class="text_5"></span><span class="text_5">only present on privilege change</span></p>
	<p class="block_19">error<span class="text_21"> </span>code</p>
	<p class="block_19">(</p>
	<p class="block_19">empty</p>
	<p class="block_19">)</p>
	<p class="block_19">ss</p>
	<p class="block_19">esp</p>
	<p class="block_19">eflags</p>
	<p class="block_19">cs</p>
	<p class="block_19">eip</p>
	<p class="block_19">esp</p>
	<p class="block_19">sp<span class="text_16"> </span>from<span class="text_18"> </span>task<span class="text_18"> </span>segment</p>
	<p class="block_19">error<span class="text_21"> </span>code</p>
	<p class="block_19">(</p>
	<p class="block_19">empty</p>
	<p class="block_19">)</p>
	<p class="block_19">ss</p>
	<p class="block_19">esp</p>
	<p class="block_19">eflags</p>
	<p class="block_19">cs</p>
	<p class="block_19">eip</p>
	<p class="block_19">esp</p>
	<p class="block_19">sp<span class="text_16"> </span>from<span class="text_18"> </span>task<span class="text_18"> </span>segment</p>
	<p class="block_33"><b class="calibre2">Figure 3-1</b>. Kernel stack after an int instruction.</p>
	<div class="calibre5">
	<div class="block_115"><span class="bullet_">• </span><span class="calibre6">Push <span class="text_3">%esp.</span></span></div>
	<div class="block_116"><span class="bullet_">• </span><span class="calibre6">Push <span class="text_3">%eflags.</span></span></div>
	<div class="block_117"><span class="bullet_">• </span><span class="calibre6">Push <span class="text_3">%cs.</span></span></div>
	<div class="block_118"><span class="bullet_">• </span><span class="calibre6">Push <span class="text_3">%eip.</span></span></div>
	<div class="block_119"><span class="bullet_">• </span><span class="calibre6">Clear some bits of <span class="text_3">%eflags.</span></span></div>
	<div class="block_113"><span class="bullet_">• </span><span class="calibre6">Set <span class="text_3">%cs </span>and <span class="text_3">%eip </span>to the values in the descriptor.</span></div>
</div>
	<p class="block_120"><span class="text_6"></span><span class="text_7">The </span><span class="text_8">int </span><span class="text_7">instruction is a complex instruction, and one might wonder whether all these actions are necessary. The check CPL &lt;= DPL allows the kernel to forbid systems for some privilege levels. For example, for a user program to execute </span><span class="text_8">int </span><span class="text_7">instruction succesfully, the DPL must be 3. If the user program doesn’t have the appropriate privilege, then </span><span class="text_8">int </span><span class="text_7">instruction will result in </span><span class="text_8">int </span><span class="text_7">13, which is a general protection fault. As another example, the </span><span class="text_8">int </span><span class="text_7">instruction cannot use the user stack to save values, because the user might not have set up an appropriate stack so that hardware uses the stack specified in the task segments, which is setup in kernel mode.</span></p>
	<p class="block_15">Figure 3-1 shows the stack after an <span class="text_3">int </span>instruction completes and there was a privilege-level change (the privilege level in the descriptor is lower than CPL). If the <span class="text_3">int </span>instruction didn’t require a privilege-level change, the x86 won’t save <span class="text_3">%ss </span>and <span class="text_3">%esp. </span>After both cases, <span class="text_3">%eip </span>is pointing to the address specified in the descriptor table, and the instruction at that address is the next instruction to be executed and the first instruction of the handler for <span class="text_3">int </span><span class="text_14">n</span>. It is job of the operating system to implement these handlers, and below we will see what xv6 does.</p>
	<p class="block_80">An operating system can use the <span class="text_3">iret </span>instruction to return from an <span class="text_3">int </span>instruction. It pops the saved values during the <span class="text_3">int </span>instruction from the stack, and resumes execution at the saved <span class="text_3">%eip.</span></p>
	<h3 class="block_90">Code: The first system call</h3>
	<p class="block_121"><span class="text_7">Chapter 1 ended with </span><span class="text_8">initcode.S </span><span class="text_7">invoking a system call. Let’s look at that again </span><span class="text_6">(8213)</span><span class="text_7">. The process pushed the arguments for an </span><span class="text_8">exec </span><span class="text_7">call on the process’s stack, and put the system call number in </span><span class="text_8">%eax. </span><span class="text_7">The system call numbers match the entries in the syscalls array, a table of function pointers </span><span class="text_6">(3600)</span><span class="text_7">. We need to arrange that the </span><span class="text_8">int </span><span class="text_7">instruction switches the processor from user mode to kernel mode, that the kernel invokes the right kernel function (i.e., </span><span class="text_8">sys_exec</span><span class="text_7">), and that the kernel can retrieve the arguments for </span><span class="text_8">sys_exec</span><span class="text_7">. The next few subsections describes how xv6 arranges this for system calls, and then we will discover that we can reuse the same code for interrupts and exceptions.</span></p>
	<h3 class="block_17">Code: Assembly trap handlers</h3>
	<p class="block_15">Xv6 must set up the x86 hardware to do something sensible on encountering an <span class="text_3">int </span>instruction, which causes the processor to generate a trap. The x86 allows for 256 different interrupts. Interrupts 0-31 are defined for software exceptions, like divide errors or attempts to access invalid memory addresses. Xv6 maps the 32 hardware interrupts to the range 32-63 and uses interrupt 64 as the system call interrupt.</p>
	<p class="block_18"><span class="text_8">Tvinit </span><span class="text_6">(3317)</span><span class="text_7">, called from </span><span class="text_8">main</span><span class="text_7">, sets up the 256 entries in the table </span><span class="text_8">idt</span><span class="text_7">. Interrupt </span><span class="text_8">i </span><span class="text_7">is handled by the code at the address in </span><span class="text_8">vectors[i]</span><span class="text_7">. Each entry point is different, because the x86 does not provide the trap number to the interrupt handler. Using 256 different handlers is the only way to distinguish the 256 cases.</span></p>
	<p class="block_15"><span class="text_3">Tvinit </span>handles <span class="text_3">T_SYSCALL</span>, the user system call trap, specially: it specifies that the gate is of type ‘‘trap’’ by passing a value of <span class="text_3">1 </span>as second argument. Trap gates don’t clear the <span class="text_3">FL </span>flag, allowing other interrupts during the system call handler.</p>
	<p class="block_15">The kernel also sets the system call gate privilege to <span class="text_3">DPL_USER</span>, which allows a user program to generate the trap with an explicit <span class="text_3">int </span>instruction. xv6 doesn’t allow processes to raise other interrupts (e.g., device interrupts) with <span class="text_3">int</span>; if they try, they will encounter a general protection exception, which goes to vector 13.</p>
	<p class="block_18"><span class="text_7">When changing protection levels from user to kernel mode, the kernel shouldn’t use the stack of the user process, because it may not be valid. The user process may be malicious or contain an error that causes the user </span><span class="text_8">%esp </span><span class="text_7">to contain an address that is not part of the process’s user memory. Xv6 programs the x86 hardware to perform a stack switch on a trap by setting up a task segment descriptor through which the hardware loads a stack segment selector and a new value for </span><span class="text_8">%esp. </span><span class="text_7">The function </span><span class="text_8">switchuvm </span><span class="text_6">(1873) </span><span class="text_7">stores the address of the top of the kernel stack of the user process into the task segment descriptor.</span></p>
	<p class="block_15">When a trap occurs, the processor hardware does the following. If the processor was executing in user mode, it loads <span class="text_3">%esp </span>and <span class="text_3">%ss </span>from the task segment descriptor, pushes the old user <span class="text_3">%ss </span>and <span class="text_3">%esp </span>onto the new stack. If the processor was executing in kernel mode, none of the above happens. The processor then pushes the <span class="text_3">%eflags, %cs, </span>and <span class="text_3">%eip </span>registers. For some traps, the processor also pushes an error word. The processor then loads <span class="text_3">%eip </span>and <span class="text_3">%cs </span>from the relevant IDT entry.</p>
	<p class="block_18"><span class="text_7">xv6 uses a Perl script </span><span class="text_6">(3200) </span><span class="text_7">to generate the entry points that the IDT entries point to. Each entry pushes an error code if the processor didn’t, pushes the interrupt number, and then jumps to </span><span class="text_8">alltraps</span><span class="text_7">.</span></p>
	<p class="block_122"><span class="text_8">Alltraps </span><span class="text_6">(3254) </span><span class="text_7">continues to save processor registers: it pushes </span><span class="text_8">%ds, %es, %fs,</span></p>
	<p class="block_88"><span class="text_8">%gs, </span><span class="text_7">and the general-purpose registers </span><span class="text_6">(3255-3260)</span><span class="text_7">. The result of this effort is that the kernel stack now contains a </span><span class="text_8">struct trapframe </span><span class="text_6">(0602) </span><span class="text_7">containing the processor registers at the time of the trap (see Figure 3-2). The processor pushes </span><span class="text_8">%ss, %esp, %eflags, %cs, </span><span class="text_7">and </span><span class="text_8">%eip. </span><span class="text_7">The processor or the trap vector pushes an error number, and </span><span class="text_8">alltraps </span><span class="text_7">pushes the rest. The trap frame contains all the information necessary to restore the user mode processor registers when the kernel returns to the current process, so that the processor can continue exactly as it was when the trap started. Recall from Chapter 2, that </span><span class="text_8">userinit </span><span class="text_7">build a trapframe by hand to achieve this goal (see Figure 1-4).</span></p>
	<p class="block_15"><img alt="Image" src="images/image-1.png" class="calibre7"/>In the case of the first system call, the saved <span class="text_3">%eip </span>is the address of the instruction right after the <span class="text_3">int </span>instruction. <span class="text_3">%cs </span>is the user code segment selector. <span class="text_3">%eflags </span>is the content of the eflags register at the point of executing the <span class="text_3">int </span>instruction. As part of saving the general-purpose registers, <span class="text_3">alltraps </span>also saves <span class="text_3">%eax, </span>which contains the system call number for the kernel to inspect later.</p>
	<p class="block_15">Now that the user mode processor registers are saved, <span class="text_3">alltraps </span>can finishing setting up the processor to run kernel C code. The processor set the selectors <span class="text_3">%cs </span>and</p>
	<p class="block_88"><span class="text_8">%ss </span><span class="text_7">before entering the handler; </span><span class="text_8">alltraps </span><span class="text_7">sets </span><span class="text_8">%ds </span><span class="text_7">and </span><span class="text_8">%es </span><span class="text_6">(3263-3265)</span><span class="text_7">. It sets </span><span class="text_8">%fs </span><span class="text_7">and </span><span class="text_8">%gs </span><span class="text_7">to point at the </span><span class="text_8">SEG_KCPU </span><span class="text_7">per-CPU data segment </span><span class="text_6">(3266-3268)</span><span class="text_7">.</span></p>
	<p class="block_18"><span class="text_7">Once the segments are set properly, </span><span class="text_8">alltraps </span><span class="text_7">can call the C trap handler </span><span class="text_8">trap</span><span class="text_7">. It pushes </span><span class="text_8">%esp, </span><span class="text_7">which points at the trap frame it just constructed, onto the stack as an argument to </span><span class="text_8">trap </span><span class="text_6">(3271)</span><span class="text_7">. Then it calls </span><span class="text_8">trap </span><span class="text_6">(3272)</span><span class="text_7">. After </span><span class="text_8">trap </span><span class="text_7">returns, </span><span class="text_8">alltraps </span><span class="text_7">pops the argument off the stack by adding to the stack pointer </span><span class="text_6">(3273) </span><span class="text_7">and then starts executing the code at label </span><span class="text_8">trapret</span><span class="text_7">. We traced through this code in Chapter 2 when the first user process ran it to exit to user space. The same sequence happens here: popping through the trap frame restores the user mode registers and then </span><span class="text_8">iret </span><span class="text_7">jumps back into user space.</span></p>
	<p class="block_80">The discussion so far has talked about traps occurring in user mode, but traps can also happen while the kernel is executing. In that case the hardware does not switch stacks or save the stack pointer or stack segment selector; otherwise the same steps occur as in traps from user mode, and the same xv6 trap handling code executes. When <span class="text_3">iret </span>later restores a kernel mode <span class="text_3">%cs, </span>the processor continues executing in kernel mode.</p>
	<h3 class="block_17">Code: C trap handler</h3>
	<p class="block_18"><span class="text_7">We saw in the last section that each handler sets up a trap frame and then calls the C function </span><span class="text_8">trap</span><span class="text_7">. </span><span class="text_8">Trap </span><span class="text_6">(3351) </span><span class="text_7">looks at the hardware trap number </span><span class="text_8">tf-&gt;trapno </span><span class="text_7">to decide why it has been called and what needs to be done. If the trap is </span><span class="text_8">T_SYSCALL</span><span class="text_7">, </span><span class="text_8">trap </span><span class="text_7">calls the system call handler </span><span class="text_8">syscall</span><span class="text_7">. We’ll revisit the two </span><span class="text_8">proc-&gt;killed </span><span class="text_7">checks in Chapter 5.</span></p>
	<p class="block_14">After checking for a system call, trap looks for hardware interrupts (which we discuss below). In addition to the expected hardware devices, a trap can be caused by a spurious interrupt, an unwanted hardware interrupt.</p>
	<p class="block_15">If the trap is not a system call and not a hardware device looking for attention, <span class="text_3">trap </span>assumes it was caused by incorrect behavior (e.g., divide by zero) as part of the code that was executing before the trap. If the code that caused the trap was a user program, xv6 prints details and then sets <span class="text_3">cp-&gt;killed </span>to remember to clean up the user process. We will look at how xv6 does this cleanup in Chapter 5.</p>
	<p class="block_123">If it was the kernel running, there must be a kernel bug: <span class="text_3">trap </span>prints details about the surprise and then calls <span class="text_3">panic</span>.</p>
	<h3 class="block_124">Code: System calls</h3>
	<p class="block_18"><span class="text_7">For system calls, </span><span class="text_8">trap </span><span class="text_7">invokes </span><span class="text_8">syscall </span><span class="text_6">(3625)</span><span class="text_7">. </span><span class="text_8">Syscall </span><span class="text_7">loads the system call number from the trap frame, which contains the saved </span><span class="text_8">%eax, </span><span class="text_7">and indexes into the system call tables. For the first system call, </span><span class="text_8">%eax </span><span class="text_7">contains the value </span><span class="text_8">SYS_exec </span><span class="text_6">(3457)</span><span class="text_7">, and </span><span class="text_8">syscall </span><span class="text_7">will invoke the </span><span class="text_8">SYS_exec</span><span class="text_7">’th entry of the system call table, which corresponds to invoking </span><span class="text_8">sys_exec</span><span class="text_7">.</span></p>
	<p class="block_18"><span class="text_8">Syscall </span><span class="text_7">records the return value of the system call function in </span><span class="text_8">%eax. </span><span class="text_7">When the trap returns to user space, it will load the values from </span><span class="text_8">cp-&gt;tf </span><span class="text_7">into the machine registers. Thus, when </span><span class="text_8">exec </span><span class="text_7">returns, it will return the value that the system call handler returned </span><span class="text_6">(3631)</span><span class="text_7">. System calls conventionally return negative numbers to indicate errors, positive numbers for success. If the system call number is invalid, </span><span class="text_8">syscall </span><span class="text_7">prints an error and returns –1.</span></p>
	<p class="block_15">Later chapters will examine the implementation of particular system calls. This chapter is concerned with the mechanisms for system calls. There is one bit of mechanism left: finding the system call arguments. The helper functions argint and argptr, argstr retrieve the <span class="text_14">n</span>’th system call argument, as either an integer, pointer, or a string. <span class="text_3">argint </span>uses the user-space <span class="text_3">%esp </span>register to locate the <span class="text_14">n’th </span>argument: <span class="text_3">%esp </span>points at the return address for the system call stub. The arguments are right above it, at <span class="text_3">%esp+4. </span>Then the nth argument is at <span class="text_3">%esp+4+4*n.</span></p>
	<p class="block_15"><span class="text_3">argint </span>calls <span class="text_3">fetchint </span>to read the value at that address from user memory and write it to <span class="text_3">*ip</span>. <span class="text_3">fetchint </span>can simply cast the address to a pointer, because the user and the kernel share the same page table, but the kernel must verify that the pointer by the user is indeed a pointer in the user part of the address space. The kernel has set up the page-table hardware to make sure that the process cannot access memory outside its local private memory: if a user program tries to read or write memory at an address of <span class="text_3">p-&gt;sz </span>or above, the processor will cause a segmentation trap, and trap will kill the process, as we saw above. Now though, the kernel is running and it can derefence any address that the user might have passed, so it must check explicitly that the address is below <span class="text_3">p-&gt;sz argptr </span>is similar in purpose to <span class="text_3">argint</span>: it interprets the <span class="text_14">n</span>th system call argu-</p>
	<p class="block_26">ment. <span class="text_3">argptr </span>calls <span class="text_3">argint </span>to fetch the argument as an integer and then checks if the integer as a user pointer is indeed in the user part of the address space. Note that two checks occur during a call to code argptr . First, the user stack pointer is checked during the fetching of the argument. Then the argument, itself a user pointer, is checked. <span class="text_3">argstr </span>is the final member of the system call argument trio. It interprets the <span class="text_14">n</span>th argument as a pointer. It ensures that the pointer points at a NUL-terminated string and that the complete string is located below the end of the user part of the address space.</p>
	<p class="block_125">The system call implementations (for example, sysproc.c and sysfile.c) are typically wrappers: they decode the arguments using <span class="text_3">argint</span>, <span class="text_3">argptr</span>, and <span class="text_3">argstr </span>and then call the real implementations. In chapter 2, <span class="text_3">sys_exec </span>uses these functions to get at its arguments.</p>
	<h3 class="block_17">Code: Interrupts</h3>
	<p class="block_14">Devices on the motherboard can generate interrupts, and xv6 must setup the hardware to handle these interrupts. Without device support xv6 wouldn’t be usable; a user couldn’t type on the keyboard, a file system couldn’t store data on disk, etc. Fortunately, adding interrupts and support for simple devices doesn’t require much additional complexity. As we will see, interrupts can use the same code as for systems calls and exceptions.</p>
	<p class="block_14">Interrupts are similar to system calls, except devices generate them at any time. There is hardware on the motherboard to signal the CPU when a device needs attention (e.g., the user has typed a character on the keyboard). We must program the device to generate an interrupt, and arrange that a CPU receives the interrupt.</p>
	<p class="block_14">Let’s look at the timer device and timer interrupts. We would like the timer hardware to generate an interrupt, say, 100 times per second so that the kernel can track the passage of time and so the kernel can time-slice among multiple running processes. The choice of 100 times per second allows for decent interactive performance while not swamping the processor with handling interrupts.</p>
	<p class="block_15">Like the x86 processor itself, PC motherboards have evolved, and the way interrupts are provided has evolved too. The early boards had a simple programmable interrupt controler (called the PIC), and you can find the code to manage it in <span class="text_3">picirq.c</span>.</p>
	<p class="block_15">With the advent of multiprocessor PC boards, a new way of handling interrupts was needed, because each CPU needs an interrupt controller to handle interrupts sent to it, and there must be a method for routing interrupts to processors. This way consists of two parts: a part that is in the I/O system (the IO APIC, <span class="text_3">ioapic.c), </span>and a part that is attached to each processor (the local APIC, <span class="text_3">lapic.c). </span>Xv6 is designed for a board with multiple processors, and each processor must be programmed to receive interrupts.</p>
	<p class="block_18"><span class="text_7">To also work correctly on uniprocessors, Xv6 programs the programmable interrupt controler (PIC) </span><span class="text_6">(7432)</span><span class="text_7">. Each PIC can handle a maximum of 8 interrupts (i.e., devices) and multiplex them on the interrupt pin of the processor. To allow for more than 8 devices, PICs can be cascaded and typically boards have at least two. Using </span><span class="text_8">inb </span><span class="text_7">and </span><span class="text_8">outb </span><span class="text_7">instructions Xv6 programs the master to generate IRQ 0 through 7 and the slave to generate IRQ 8 through 16. Initially xv6 programs the PIC to mask all interrupts. The code in </span><span class="text_8">timer.c </span><span class="text_7">sets timer 1 and enables the timer interrupt on the PIC </span><span class="text_6">(8074)</span><span class="text_7">. This description omits some of the details of programming the PIC. These details of the PIC (and the IOAPIC and LAPIC) are not important to this text but the interested reader can consult the manuals for each device, which are referenced in the source files.</span></p>
	<p class="block_18"><span class="text_7">On multiprocessors, xv6 must program the IOAPIC, and the LAPIC on each processor. The IO APIC has a table and the processor can program entries in the table through memory-mapped I/O, instead of using </span><span class="text_8">inb </span><span class="text_7">and </span><span class="text_8">outb </span><span class="text_7">instructions. During initialization, xv6 programs to map interrupt 0 to IRQ 0, and so on, but disables them all. Specific devices enable particular interrupts and say to which processor the interrupt should be routed. For example, xv6 routes keyboard interrupts to processor 0 </span><span class="text_6">(8016)</span><span class="text_7">. Xv6 routes disk interrupts to the highest numbered processor on the system, as we will see below.</span></p>
	<p class="block_18"><span class="text_7">The timer chip is inside the LAPIC, so that each processor can receive timer interrupts independently. Xv6 sets it up in </span><span class="text_8">lapicinit </span><span class="text_6">(7151)</span><span class="text_7">. The key line is the one that programs the timer </span><span class="text_6">(7164)</span><span class="text_7">. This line tells the LAPIC to periodically generate an interrupt at </span><span class="text_8">IRQ_TIMER, </span><span class="text_7">which is IRQ 0. Line </span><span class="text_6">(7193) </span><span class="text_7">enables interrupts on a CPU’s LAPIC, which will cause it to deliver interrupts to the local processor.</span></p>
	<p class="block_18"><span class="text_7">A processor can control if it wants to receive interrupts through the </span><span class="text_8">IF </span><span class="text_7">flag in the eflags register. The instruction </span><span class="text_8">cli </span><span class="text_7">disables interrupts on the processor by clearing </span><span class="text_8">IF</span><span class="text_7">, and </span><span class="text_8">sti </span><span class="text_7">enables interrupts on a processor. Xv6 disables interrupts during booting of the main cpu </span><span class="text_6">(8912) </span><span class="text_7">and the other processors </span><span class="text_6">(1126)</span><span class="text_7">. The scheduler on each processor enables interrupts </span><span class="text_6">(2714)</span><span class="text_7">. To control that certain code fragments are not interrupted, xv6 disables interrupts during these code fragments (e.g., see </span><span class="text_8">switchuvm </span><span class="text_6">(1873)</span><span class="text_7">).</span></p>
	<p class="block_126"><span class="text_7">The timer interrupts through vector 32 (which xv6 chose to handle IRQ 0), which xv6 setup in </span><span class="text_8">idtinit </span><span class="text_6">(1265)</span><span class="text_7">. The only difference between vector 32 and vector 64 (the one for system calls) is that vector 32 is an interrupt gate instead of a trap gate. Interrupt gates clear </span><span class="text_8">IF</span><span class="text_7">, so that the interrupted processor doesn’t receive interrupts while it is handling the current interrupt. From here on until </span><span class="text_8">trap</span><span class="text_7">, interrupts follow the same code path as system calls and exceptions, building up a trap frame.</span></p>
	<p class="block_89"><span class="text_8">Trap </span><span class="text_7">when it’s called for a time interrupt, does just two things: increment the ticks variable </span><span class="text_6">(3367)</span><span class="text_7">, and call </span><span class="text_8">wakeup</span><span class="text_7">. The latter, as we will see in Chapter 5, may cause the interrupt to return in a different process.</span></p>
	<h3 class="block_56">Drivers</h3>
	<p class="block_26">A <span class="text_3">driver </span>is the piece of code in an operating system that manages a particular device: it provides interrupt handlers for a device, causes a device to perform operations, causes a device to generate interrupts, etc. Driver code can be tricky to write because a driver executes concurrently with the device that it manages. In addition, the driver must understand the device’s interface (e.g., which I/O ports do what), and that interface can be complex and poorly documented.</p>
	<p class="block_40">The disk driver provides a good example in xv6. The disk driver copies data from and back to the disk. Disk hardware traditionally presents the data on the disk as a numbered sequence of 512-byte <i class="calibre3">blocks </i>(also called <i class="calibre3">sectors</i>): sector 0 is the first 512 bytes, sector 1 is the next, and so on. To represent disk sectors an operating system has a structure that corresponds to one sector. The data stored in this structure is often out of sync with the disk: it might have not yet been read in from disk (the disk is working on it but hasn’t returned the sector’s content yet), or it might have been updated but not yet written out. The driver must ensure that the rest of xv6 doesn’t get confused when the structure is out of sync with the disk.</p>
	<h3 class="block_17">Code: Disk driver</h3>
	<p class="block_14">The IDE device provides access to disks connected to the PC standard IDE controller. IDE is now falling out of fashion in favor of SCSI and SATA, but the interface is simple and lets us concentrate on the overall structure of a driver instead of the details of a particular piece of hardware.</p>
	<p class="block_18"><span class="text_7">The disk driver represent disk sectors with a data structure called a </span><span class="text_8">buffer</span><span class="text_7">, </span><span class="text_8">struct buf </span><span class="text_6">(3750)</span><span class="text_7">. Each buffer represents the contents of one sector on a particular disk device. The </span><span class="text_8">dev </span><span class="text_7">and </span><span class="text_8">sector </span><span class="text_7">fields give the device and sector number and the </span><span class="text_8">data </span><span class="text_7">field is an in-memory copy of the disk sector.</span></p>
	<p class="block_15">The <span class="text_3">flags </span>track the relationship between memory and disk: the <span class="text_3">B_VALID </span>flag means that <span class="text_3">data </span>has been read in, and the <span class="text_3">B_DIRTY </span>flag means that <span class="text_3">data </span>needs to be written out. The <span class="text_3">B_BUSY </span>flag is a lock bit; it indicates that some process is using the buffer and other processes must not. When a buffer has the <span class="text_3">B_BUSY </span>flag set, we say the buffer is locked.</p>
	<p class="block_18"><span class="text_7">The kernel initializes the disk driver at boot time by calling </span><span class="text_8">ideinit </span><span class="text_6">(4151) </span><span class="text_7">from </span><span class="text_8">main </span><span class="text_6">(1234)</span><span class="text_7">. </span><span class="text_8">Ideinit </span><span class="text_7">calls </span><span class="text_8">picenable </span><span class="text_7">and </span><span class="text_8">ioapicenable </span><span class="text_7">to enable the </span><span class="text_8">IDE_IRQ </span><span class="text_7">interrupt </span><span class="text_6">(4156-4157)</span><span class="text_7">. The call to </span><span class="text_8">picenable </span><span class="text_7">enables the interrupt on a uniprocessor; </span><span class="text_8">ioapicenable </span><span class="text_7">enables the interrupt on a multiprocessor, but only on the last CPU (</span><span class="text_8">ncpu-1</span><span class="text_7">): on a two-processor system, CPU 1 handles disk interrupts.</span></p>
	<p class="block_18"><span class="text_7">Next, </span><span class="text_8">ideinit </span><span class="text_7">probes the disk hardware. It begins by calling </span><span class="text_8">idewait </span><span class="text_6">(4158) </span><span class="text_7">to wait for the disk to be able to accept commands. A PC motherboard presents the status bits of the disk hardware on I/O port </span><span class="text_8">0x1f7</span><span class="text_7">. </span><span class="text_8">Idewait </span><span class="text_6">(4133) </span><span class="text_7">polls the status bits until the busy bit (</span><span class="text_8">IDE_BSY</span><span class="text_7">) is clear and the ready bit (</span><span class="text_8">IDE_DRDY</span><span class="text_7">) is set.</span></p>
	<p class="block_15">Now that the disk controller is ready, <span class="text_3">ideinit </span>can check how many disks are present. It assumes that disk 0 is present, because the boot loader and the kernel were both loaded from disk 0, but it must check for disk 1. It writes to I/O port <span class="text_3">0x1f6 </span>to select disk 1 and then waits a while for the status bit to show that the disk is ready</p>
	<p class="block_88"><span class="text_6">(4160-4167)</span><span class="text_7">. If not, </span><span class="text_8">ideinit </span><span class="text_7">assumes the disk is absent.</span></p>
	<p class="block_15">After <span class="text_3">ideinit</span>, the disk is not used again until the buffer cache calls <span class="text_3">iderw</span>, which updates a locked buffer as indicated by the flags. If <span class="text_3">B_DIRTY </span>is set, <span class="text_3">iderw </span>writes the buffer to the disk; if <span class="text_3">B_VALID </span>is not set, <span class="text_3">iderw </span>reads the buffer from the disk.</p>
	<p class="block_15">Disk accesses typically take milliseconds, a long time for a processor. The boot loader issues disk read commands and reads the status bits repeatedly until the data is ready. This <span class="text_3">polling </span>or <span class="text_3">busy waiting </span>is fine in a boot loader, which has nothing better to do. In an operating system, however, it is more efficient to let another process run on the CPU and arrange to receive an interrupt when the disk operation has completed. <span class="text_3">Iderw </span>takes this latter approach, keeping the list of pending disk requests in a queue and using interrupts to find out when each request has finished. Although <span class="text_3">iderw </span>maintains a queue of requests, the simple IDE disk controller can only handle one operation at a time. The disk driver maintains the invariant that it has sent the buffer at the front of the queue to the disk hardware; the others are simply waiting their turn.</p>
	<p class="block_18"><span class="text_8">Iderw </span><span class="text_6">(4254) </span><span class="text_7">adds the buffer </span><span class="text_8">b </span><span class="text_7">to the end of the queue </span><span class="text_6">(4267-4271)</span><span class="text_7">. If the buffer is at the front of the queue, </span><span class="text_8">iderw </span><span class="text_7">must send it to the disk hardware by calling </span><span class="text_8">idestart </span><span class="text_6">(4224-4226)</span><span class="text_7">; otherwise the buffer will be started once the buffers ahead of it are taken care of.</span></p>
	<p class="block_18"><span class="text_8">Idestart </span><span class="text_6">(4175) </span><span class="text_7">issues either a read or a write for the buffer’s device and sector, according to the flags. If the operation is a write, idestart must supply the data now </span><span class="text_6">(4189) </span><span class="text_7">and the interrupt will signal that the data has been written to disk. If the operation is a read, the interrupt will signal that the data is ready, and the handler will read it. Note that </span><span class="text_8">idestart </span><span class="text_7">has detailed knowledge about the IDE device, and writes the right values at the right ports. If any of these </span><span class="text_8">outb </span><span class="text_7">statements is wrong, the IDE will do something differently than what we want. Getting these details right is one reason why writing device drivers is challenging.</span></p>
	<p class="block_18"><span class="text_7">Having added the request to the queue and started it if necessary, </span><span class="text_8">iderw </span><span class="text_7">must wait for the result. As discussed above, polling does not make efficient use of the CPU. Instead, </span><span class="text_8">iderw </span><span class="text_7">sleeps, waiting for the interrupt handler to record in the buffer’s flags that the operation is done </span><span class="text_6">(4278-4279)</span><span class="text_7">. While this process is sleeping, xv6 will schedule other processes to keep the CPU busy.</span></p>
	<p class="block_127"><span class="text_7">Eventually, the disk will finish its operation and trigger an interrupt. </span><span class="text_8">trap </span><span class="text_7">will call </span><span class="text_8">ideintr </span><span class="text_7">to handle it </span><span class="text_6">(3374)</span><span class="text_7">. </span><span class="text_8">Ideintr </span><span class="text_6">(4202) </span><span class="text_7">consults the first buffer in the queue to find out which operation was happening. If the buffer was being read and the disk controller has data waiting, </span><span class="text_8">ideintr </span><span class="text_7">reads the data into the buffer with </span><span class="text_8">insl </span><span class="text_6">(42154217)</span><span class="text_7">. Now the buffer is ready: </span><span class="text_8">ideintr </span><span class="text_7">sets </span><span class="text_8">B_VALID</span><span class="text_7">, clears </span><span class="text_8">B_DIRTY</span><span class="text_7">, and wakes up any process sleeping on the buffer </span><span class="text_6">(4219-4222)</span><span class="text_7">. Finally, </span><span class="text_8">ideintr </span><span class="text_7">must pass the next waiting buffer to the disk </span><span class="text_6">(4224-4226)</span><span class="text_7">.</span></p>
	<h3 class="block_17">Real world</h3>
	<p class="block_11">Supporting all the devices on a PC motherboard in its full glory is much work, because there are many devices, the devices have many features, and the protocol between device and driver can be complex. In many operating systems, the drivers together account for more code in the operating system than the core kernel.</p>
	<p class="block_15">Actual device drivers are far more complex than the disk driver in this chapter, but the basic ideas are the same: typically devices are slower than CPU, so the hardware uses interrupts to notify the operating system of status changes. Modern disk controllers typically accept a <span class="text_3">batch </span>of disk requests at a time and even reorder them to make most efficient use of the disk arm. When disks were simpler, operating system often reordered the request queue themselves.</p>
	<p class="block_14">Many operating systems have drivers for solid-state disks because they provide much faster access to data. But, although a solid-state works very differently from a traditional mechanical disk, both devices provide block-based interfaces and reading/writing blocks on a solid-state disk is still more expensive than reading/writing</p>
	<p class="block_11">RAM.</p>
	<p class="block_15">Other hardware is surprisingly similar to disks: network device buffers hold packets, audio device buffers hold sound samples, graphics card buffers hold video data and command sequences. High-bandwidth devices—disks, graphics cards, and network cards—often use direct memory access (DMA) instead of the explicit I/O (<span class="text_3">insl</span>, <span class="text_3">outsl</span>) in this driver. DMA allows the disk or other controllers direct access to physical memory. The driver gives the device the physical address of the buffer’s data field and the device copies directly to or from main memory, interrupting once the copy is complete. Using DMA means that the CPU is not involved at all in the transfer, which can be more efficient and is less taxing for the CPU’s memory caches.</p>
	<p class="block_14">Most of the devices in this chapter used I/O instructions to program them, which reflects the older nature of these devices. All modern devices are programmed using memory-mapped I/O.</p>
	<p class="block_14">Some drivers dynamically switch between polling and interrupts, because using interrupts can be expensive, but using polling can introduce delay until the driver processes an event. For example, for a network driver that receives a burst of packets, may switch from interrupts to polling since it knows that more packets must be processed and it is less expensive to process them using polling. Once no more packets need to be processed, the driver may switch back to interrupts, so that it will be alerted immediately when a new packet arrives.</p>
	<p class="block_14">The IDE driver routed interrupts statically to a particular processor. Some drivers have a sophisticated algorithm for routing interrupts to processor so that the load of processing packets is well balanced but good locality is achieved too. For example, a network driver might arrange to deliver interrupts for packets of one network connection to the processor that is managing that connection, while interrupts for packets of another connection are delivered to another processor. This routing can get quite sophisticated; for example, if some network connections are short lived while others are long lived and the operating system wants to keep all processors busy to achieve high throughput.</p>
	<p class="block_80">If user process reads a file, the data for that file is copied twice. First, it is copied from the disk to kernel memory by the driver, and then later it is copied from kernel space to user space by the <span class="text_3">read </span>system call. If the user process, then sends the data on the network, then the data is copied again twice: once from user space to kernel space and from kernel space to the network device. To support applications for which low latency is important (e.g., a Web serving static Web pages), operating systems use special code paths to avoid these many copies. As one example, in real-world operating systems, buffers typically match the hardware page size, so that read-only copies can be mapped into a process’s address space using the paging hardware, without any copying.</p>
	<h3 class="block_17">Exercises</h3>
	<ol class="list_">
	<li class="block_128">Set a breakpoint at the first instruction of syscall() to catch the very first system call(e.g., br syscall). What values are on the stack at this point? Explain the output of x/37x $esp at that breakpoint with each value labeled as to what it is (e.g., saved %ebp for trap, trapframe.eip, scratch space, etc.).</li>
	<li class="block_129">Add a new system call</li>
	<li class="block_130">Add a network driver</li>
</ol>
	<p class="block_77">Chapter 4</p>
	<h1 id="id_Toc460887578" class="block_13">Locking</h1>
	<p class="block_15">Xv6 runs on multiprocessors, computers with multiple CPUs executing code independently. These multiple CPUs operate on a single physical address space and share data structures; xv6 must introduce a coordination mechanism to keep them from interfering with each other. Even on a uniprocessor, xv6 must use some mechanism to keep interrupt handlers from interfering with non-interrupt code. Xv6 uses the same low-level concept for both: a <span class="text_3">lock</span>. A lock provides mutual exclusion, ensuring that only one CPU at a time can hold the lock. If xv6 only accesses a data structure while holding a particular lock, then xv6 can be sure that only one CPU at a time is accessing the data structure. In this situation, we say that the lock protects the data structure.</p>
	<p class="block_40">The rest of this chapter explains why xv6 needs locks, how xv6 implements them, and how it uses them. A key observation will be that if you look at a line of code in xv6, you must be asking yourself is there another processor that could change the intended behavior of the line (e.g., because another processor is also executing that line or another line of code that modifies a shared variable) and what would happen if an interrupt handler ran. In both cases, you must keep in mind that a single C statement can be several machine instructions and thus another processor or an interrupt may muck around in the middle of the C statement. You cannot assume that lines of code on the page are executed sequentially, nor can you assume that a single C statement will execute atomically. Concurrency makes reasoning about the correctness much more difficult.</p>
	<h3 class="block_17">Race conditions</h3>
	<p class="block_131"><span class="text_4">As an example on why we need locks, consider several processors sharing a single disk, such as the IDE disk in xv6. The disk driver maintains a linked list of the outstanding disk requests </span><span class="text_5">(4121) </span><span class="text_4">and processors may add new requests to the list concurrently </span><span class="text_5">(4254)</span><span class="text_4">. If there were no concurrent requests, you might implement the linked list as follows:</span></p>
	<div class="calibre8">
	<div class="block_132"><span class="bullet_">1 </span><span class="calibre6">struct list {</span></div>
	<div class="block_132"><span class="bullet_">2 </span><span class="calibre6">int data;</span></div>
	<div class="block_132"><span class="bullet_">3 </span><span class="calibre6">struct list *next;</span></div>
	<div class="block_133"><span class="bullet_">4 </span><span class="calibre6">};</span></div>
</div>
	<p class="block_134">5</p>
	<p class="block_135"><span class="text_6"></span><span class="text_27">6<span class="tab">       </span>struct list *list = 0;</span></p>
	<p class="block_134">7</p>
	<div class="calibre9">
	<div class="block_132"><span class="bullet_">8 </span><span class="calibre6">void</span></div>
	<div class="block_132"><span class="bullet_">9 </span><span class="calibre6">insert(int data)</span></div>
	<div class="block_132"><span class="bullet_">10 </span><span class="calibre6">{</span></div>
	<div class="block_132"><span class="bullet_">11 </span><span class="calibre6">struct list *l;</span></div>
</div>
	<p class="block_27"><span class="text_12"></span><span class="text_12">15<span class="tab">       </span></span><sup class="text_28">16</sup></p>
	<p class="block_136">CPU 1</p>
	<p class="block_137"></p>
	<p class="block_19">Memory</p>
	<p class="block_19">CPU2</p>
	<p class="block_19">15</p>
	<p class="block_19">l-&gt;next</p>
	<p class="block_19">16</p>
	<p class="block_19">list</p>
	<p class="block_19">list</p>
	<p class="block_19">l-&gt;next</p>
	<p class="block_19">Memory</p>
	<p class="block_19">CPU2</p>
	<p class="block_19">15</p>
	<p class="block_19">l-&gt;next</p>
	<p class="block_19">16</p>
	<p class="block_19">list</p>
	<p class="block_19">list</p>
	<p class="block_19">l-&gt;next</p>
	<p class="block_138"></p>
	<p class="block_139">Time</p>
	<p class="block_33"><b class="calibre2">Figure 4-1</b>. Example race</p>
	<p class="block_140">12</p>
	<div class="calibre10">
	<div class="block_141"><span class="bullet_">13 </span><span class="calibre6">l = malloc(sizeof *l);</span></div>
	<div class="block_141"><span class="bullet_">14 </span><span class="calibre6">l-&gt;data = data;</span></div>
	<div class="block_141"><span class="bullet_">15 </span><span class="calibre6">l-&gt;next = list;</span></div>
	<div class="block_141"><span class="bullet_">16 </span><span class="calibre6">list = l;</span></div>
	<div class="block_142"><span class="bullet_1">17 </span><span class="calibre6"><span class="text_29"></span><span class="text_8">}</span></span></div>
</div>
	<p class="block_26">Proving this implementation correct is a typical exercise in a data structures and algorithms class. Even though this implementation can be proved correct, it isn’t, at least not on a multiprocessor. If two different CPUs execute <span class="text_3">insert </span>at the same time, it could happen that both execute line 15 before either executes 16 (see Figure 4-1). If this happens, there will now be two list nodes with <span class="text_3">next </span>set to the former value of <span class="text_3">list</span>. When the two assignments to <span class="text_3">list </span>happen at line 16, the second one will overwrite the first; the node involved in the first assignment will be lost. This kind of problem is called a <span class="text_3">race condition</span>. The problem with races is that they depend on the exact timing of the two CPUs involved and how their memory operations are ordered by the memory system, and are consequently difficult to reproduce. For example, adding print statements while debugging <span class="text_3">insert </span>might change the timing of the execution enough to make the race disappear.</p>
	<p class="block_143">The typical way to avoid races is to use a lock. Locks ensure mutual exclusion, so that only one CPU can execute <span class="text_3">insert </span>at a time; this makes the scenario above impossible. The correctly locked version of the above code adds just a few lines (not numbered):</p>
	<p class="block_144">6<span class="tab">       </span>struct list *list = 0; struct lock listlock;</p>
	<p class="block_134">7</p>
	<div class="calibre9">
	<div class="block_132"><span class="bullet_">8 </span><span class="calibre6">void</span></div>
	<div class="block_132"><span class="bullet_">9 </span><span class="calibre6">insert(int data)</span></div>
	<div class="block_132"><span class="bullet_">10 </span><span class="calibre6">{</span></div>
	<div class="block_132"><span class="bullet_">11 </span><span class="calibre6">struct list *l;</span></div>
</div>
	<p class="block_145">12</p>
	<p class="block_146">acquire(&amp;listlock);</p>
	<div class="calibre8">
	<div class="block_132"><span class="bullet_">13 </span><span class="calibre6">l = malloc(sizeof *l);</span></div>
	<div class="block_132"><span class="bullet_">14 </span><span class="calibre6">l-&gt;data = data;</span></div>
	<div class="block_132"><span class="bullet_">15 </span><span class="calibre6">l-&gt;next = list;</span></div>
	<div class="block_133"><span class="bullet_">16 </span><span class="calibre6">list = l;</span></div>
</div>
	<p class="block_146">release(&amp;listlock);</p>
	<div class="calibre8">
	<div class="block_147"><span class="bullet_">17 </span><span class="calibre6">}</span></div>
</div>
	<p class="block_123">When we say that a lock protects data, we really mean that the lock protects some collection of invariants that apply to the data. Invariants are properties of data structures that are maintained across operations. Typically, an operation’s correct behavior depends on the invariants being true when the operation begins. The operation may temporarily violate the invariants but must reestablish them before finishing. For example, in the linked list case, the invariant is that <span class="text_3">list </span>points at the first node in the list and that each node’s <span class="text_3">next </span>field points at the next node. The implementation of <span class="text_3">insert </span>violates this invariant temporarily: line 13 creates a new list element <span class="text_3">l </span>with the intent that <span class="text_3">l </span>be the first node in the list, but <span class="text_3">l</span>’s next pointer does not point at the next node in the list yet (reestablished at line 15) and <span class="text_3">list </span>does not point at <span class="text_3">l </span>yet (reestablished at line 16). The race condition we examined above happened because a second CPU executed code that depended on the list invariants while they were (temporarily) violated. Proper use of a lock ensures that only one CPU at a time can operate on the data structure, so that no CPU will execute a data structure operation when the data structure’s invariants do not hold.</p>
	<h3 class="block_99">Code: Locks</h3>
	<p class="block_148"><span class="text_7">Xv6’s represents a lock as a </span><span class="text_8">struct spinlock </span><span class="text_6">(1501)</span><span class="text_7">. The critical field in the structure is </span><span class="text_8">locked</span><span class="text_7">, a word that is zero when the lock is available and non-zero when it is held. Logically, xv6 should acquire a lock by executing code like</span></p>
	<div class="calibre8">
	<div class="block_132"><span class="bullet_">21 </span><span class="calibre6">void</span></div>
	<div class="block_132"><span class="bullet_">22 </span><span class="calibre6">acquire(struct spinlock *lk)</span></div>
	<div class="block_132"><span class="bullet_">23 </span><span class="calibre6">{</span></div>
	<div class="block_132"><span class="bullet_">24 </span><span class="calibre6">for(;;) {</span></div>
	<div class="block_132"><span class="bullet_">25 </span><span class="calibre6">if(!lk-&gt;locked) { 26 <span class="tab">       </span>lk-&gt;locked = 1;</span></div>
</div>
	<div class="calibre11">
	<div class="block_132"><span class="bullet_">27 </span><span class="calibre6">break;</span></div>
	<div class="block_132"><span class="bullet_">28 </span><span class="calibre6">}</span></div>
	<div class="block_132"><span class="bullet_">29 </span><span class="calibre6">}</span></div>
	<div class="block_147"><span class="bullet_">30 </span><span class="calibre6">}</span></div>
</div>
	<p class="block_26">Unfortunately, this implementation does not guarantee mutual exclusion on a modern multiprocessor. It could happen that two (or more) CPUs simultaneously reach line 25, see that <span class="text_3">lk-&gt;locked </span>is zero, and then both grab the lock by executing lines 26 and 27. At this point, two different CPUs hold the lock, which violates the mutual exclusion property. Rather than helping us avoid race conditions, this implementation of <span class="text_3">acquire </span>has its own race condition. The problem here is that lines 25 and 26 executed as separate actions. In order for the routine above to be correct, lines 25 and 26 must execute in one <span class="text_3">atomic </span>(i.e., indivisible) step.</p>
	<p class="block_18"><span class="text_7">To execute those two lines atomically, xv6 relies on a special 386 hardware instruction, </span><span class="text_8">xchg </span><span class="text_6">(0569)</span><span class="text_7">. In one atomic operation, </span><span class="text_8">xchg </span><span class="text_7">swaps a word in memory with the contents of a register. The function </span><span class="text_8">acquire </span><span class="text_6">(1574) </span><span class="text_7">repeats this </span><span class="text_8">xchg </span><span class="text_7">instruction in a loop; each iteration reads </span><span class="text_8">lk-&gt;locked </span><span class="text_7">and atomically sets it to 1 </span><span class="text_6">(1583)</span><span class="text_7">. If the lock is held, </span><span class="text_8">lk-&gt;locked </span><span class="text_7">will already be 1, so the </span><span class="text_8">xchg </span><span class="text_7">returns 1 and the loop continues. If the </span><span class="text_8">xchg </span><span class="text_7">returns 0, however, </span><span class="text_8">acquire </span><span class="text_7">has successfully acquired the lock—</span><span class="text_8">locked </span><span class="text_7">was 0 and is now 1—so the loop can stop. Once the lock is acquired, </span><span class="text_8">acquire </span><span class="text_7">records, for debugging, the CPU and stack trace that acquired the lock. When a process acquires a lock and forget to release it, this information can help to identify the culprit. These debugging fields are protected by the lock and must only be edited while holding the lock.</span></p>
	<p class="block_149"><span class="text_7">The function </span><span class="text_8">release </span><span class="text_6">(1602) </span><span class="text_7">is the opposite of </span><span class="text_8">acquire</span><span class="text_7">: it clears the debugging fields and then releases the lock.</span></p>
	<h3 class="block_17">Modularity and recursive locks</h3>
	<p class="block_15">System design strives for clean, modular abstractions: it is best when a caller does not need to know how a callee implements particular functionality. Locks interfere with this modularity. For example, if a CPU holds a particular lock, it cannot call any function <span class="text_3">f </span>that will try to reacquire that lock: since the caller can’t release the lock until <span class="text_3">f </span>returns, if <span class="text_3">f </span>tries to acquire the same lock, it will spin forever, or deadlock.</p>
	<p class="block_15">There are no transparent solutions that allow the caller and callee to hide which locks they use. One common, transparent, but unsatisfactory solution is <span class="text_3">recursive locks</span>, which allow a callee to reacquire a lock already held by its caller. The problem with this solution is that recursive locks can’t be used to protect invariants. After <span class="text_3">insert </span>called <span class="text_3">acquire(&amp;listlock) </span>above, it can assume that no other function holds the lock, that no other function is in the middle of a list operation, and most importantly that all the list invariants hold. In a system with recursive locks, <span class="text_3">insert </span>can assume nothing after it calls <span class="text_3">acquire</span>: perhaps <span class="text_3">acquire </span>succeeded only because one of <span class="text_3">insert</span>’s caller already held the lock and was in the middle of editing the list data structure. Maybe the invariants hold or maybe they don’t. The list no longer protects them. Locks are just as important for protecting callers and callees from each other as they are for protecting different CPUs from each other; recursive locks give up that property.</p>
	<p class="block_80">Since there is no ideal transparent solution, we must consider locks part of the function’s specification. The programmer must arrange that function doesn’t invoke a function <span class="text_3">f </span>while holding a lock that <span class="text_3">f </span>needs. Locks force themselves into our abstractions.</p>
	<h3 class="block_17">Code: Using locks</h3>
	<p class="block_88"><span class="text_7">Xv6 is carefully programmed with locks to avoid race conditions. A simple example is in the IDE driver </span><span class="text_6">(4100)</span><span class="text_7">. As mentioned in the beginning of the chapter, </span><span class="text_8">iderw </span><span class="text_6">(4254) </span><span class="text_7">has a queue of disk requests and processors may add new requests to the list concurrently </span><span class="text_6">(4269)</span><span class="text_7">. To protect this list and other invariants in the driver, </span><span class="text_8">iderw </span><span class="text_7">acquires the </span><span class="text_8">idelock </span><span class="text_6">(4265) </span><span class="text_7">and releases at the end of the function. Exercise 1 explores how to trigger the race condition that we saw at the beginning of the chapter by moving the </span><span class="text_8">acquire </span><span class="text_7">to after the queue manipulation. It is worthwhile to try the exercise because it will make clear that it is not that easy to trigger the race, suggesting that it is difficult to find race-conditions bugs. It is not unlikely that xv6 has some races.</span></p>
	<p class="block_14">A hard part about using locks is deciding how many locks to use and which data and invariants each lock protects. There are a few basic principles. First, any time a variable can be written by one CPU at the same time that another CPU can read or write it, a lock should be introduced to keep the two operations from overlapping. Second, remember that locks protect invariants: if an invariant involves multiple data structures, typically all of the structures need to be protected by a single lock to ensure the invariant is maintained.</p>
	<p class="block_14">The rules above say when locks are necessary but say nothing about when locks are unnecessary, and it is important for efficiency not to lock too much, because locks reduce parallelism. If efficiency wasn’t important, then one could use a uniprocessor computer and no worry at all about locks. For protecting kernel data structures, it would suffice to create a single lock that must be acquired on entering the kernel and released on exiting the kernel. Many uniprocessor operating systems have been converted to run on multiprocessors using this approach, sometimes called a ‘‘giant kernel lock,’’ but the approach sacrifices true concurrency: only one CPU can execute in the kernel at a time. If the kernel does any heavy computation, it would be more efficient to use a larger set of more fine-grained locks, so that the kernel could execute on multiple CPUs simultaneously.</p>
	<p class="block_40">Ultimately, the choice of lock granularity is an exercise in parallel programming. Xv6 uses a few coarse data-structure specific locks; for example, xv6 uses a single lock protecting the process table and its invariants, which are described in Chapter 5. A more fine-grained approach would be to have a lock per entry in the process table so that threads working on different entries in the process table can proceed in parallel. However, it complicates operations that have invariants over the whole process table, since they might have to take out several locks. Hopefully, the examples of xv6 will help convey how to use locks.</p>
	<h3 class="block_17">Lock ordering</h3>
	<p class="block_11">If a code path through the kernel must take out several locks, it is important that all code paths acquire the locks in the same order. If they don’t, there is a risk of deadlock. Let’s say two code paths in xv6 needs locks A and B, but code path 1 acquires locks in the order A and B, and the other code acquires them in the order B and A. This situation can result in a deadlock, because code path 1 might acquire lock A and before it acquires lock B, code path 2 might acquire lock B. Now neither code path can proceed, because code path 1 needs lock B, which code path 2 holds, and code path 2 needs lock A, which code path 1 holds. To avoid such deadlocks, all code paths must acquire locks in the same order. Deadlock avoidance is another example illustrating why locks must be part of a function’s specification: the caller must invoke functions in a consistent order so that the functions acquire locks in the same order.</p>
	<p class="block_125">Because xv6 uses coarse-grained locks and xv6 is simple, xv6 has few lock-order chains. The longest chain is only two deep. For example, <span class="text_3">ideintr </span>holds the ide lock while calling <span class="text_3">wakeup</span>, which acquires the <span class="text_3">ptable </span>lock. There are a number of other examples involving <span class="text_3">sleep </span>and <span class="text_3">wakeup</span>. These orderings come about because <span class="text_3">sleep </span>and <span class="text_3">wakeup </span>have a complicated invariant, as discussed in Chapter 5. In the file system there are a number of examples of chains of two because the file system must, for example, acquire a lock on a directory and the lock on a file in that directory to unlink a file from its parent directory correctly. Xv6 always acquires the locks in the order first parent directory and then the file.</p>
	<h3 class="block_17">Interrupt handlers</h3>
	<p class="block_88"><span class="text_7">Xv6 uses locks to protect interrupt handlers running on one CPU from non-interrupt code accessing the same data on another CPU. For example, the timer interrupt handler </span><span class="text_6">(3364) </span><span class="text_7">increments </span><span class="text_8">ticks </span><span class="text_7">but another CPU might be in </span><span class="text_8">sys_sleep </span><span class="text_7">at the same time, using the variable </span><span class="text_6">(3723)</span><span class="text_7">. The lock </span><span class="text_8">tickslock </span><span class="text_7">synchronizes access by the two CPUs to the single variable.</span></p>
	<p class="block_15">Interrupts can cause concurrency even on a single processor: if interrupts are enabled, kernel code can be stopped at any moment to run an interrupt handler instead. Suppose <span class="text_3">iderw </span>held the <span class="text_3">idelock </span>and then got interrupted to run <span class="text_3">ideintr</span>. <span class="text_3">Ideintr </span>would try to lock <span class="text_3">idelock</span>, see it was held, and wait for it to be released. In this situation, <span class="text_3">idelock </span>will never be released—only <span class="text_3">iderw </span>can release it, and <span class="text_3">iderw </span>will not continue running until <span class="text_3">ideintr </span>returns—so the processor, and eventually the whole system, will deadlock.</p>
	<p class="block_18"><span class="text_7">To avoid this situation, if a lock is used by an interrupt handler, a processor must never hold that lock with interrupts enabled. Xv6 is more conservative: it never holds any lock with interrupts enabled. It uses </span><span class="text_8">pushcli </span><span class="text_6">(1655) </span><span class="text_7">and </span><span class="text_8">popcli </span><span class="text_6">(1666) </span><span class="text_7">to manage a stack of ‘‘disable interrupts’’ operations (</span><span class="text_8">cli </span><span class="text_7">is the x86 instruction that disables interrupts. </span><span class="text_8">Acquire </span><span class="text_7">calls </span><span class="text_8">pushcli </span><span class="text_7">before trying to acquire a lock </span><span class="text_6">(1576)</span><span class="text_7">, and </span><span class="text_8">release </span><span class="text_7">calls </span><span class="text_8">popcli </span><span class="text_7">after releasing the lock </span><span class="text_6">(1621)</span><span class="text_7">. </span><span class="text_8">Pushcli </span><span class="text_6">(1655) </span><span class="text_7">and </span><span class="text_8">popcli </span><span class="text_6">(1666) </span><span class="text_7">are more than just wrappers around </span><span class="text_8">cli </span><span class="text_7">and </span><span class="text_8">sti</span><span class="text_7">: they are counted, so that it takes two calls to </span><span class="text_8">popcli </span><span class="text_7">to undo two calls to </span><span class="text_8">pushcli</span><span class="text_7">; this way, if code acquires two different locks, interrupts will not be reenabled until both locks have been released.</span></p>
	<p class="block_18"><span class="text_7">It is important that </span><span class="text_8">acquire </span><span class="text_7">call </span><span class="text_8">pushcli </span><span class="text_7">before the </span><span class="text_8">xchg </span><span class="text_7">that might acquire the lock </span><span class="text_6">(1583)</span><span class="text_7">. If the two were reversed, there would be a few instruction cycles when the lock was held with interrupts enabled, and an unfortunately timed interrupt would deadlock the system. Similarly, it is important that </span><span class="text_8">release </span><span class="text_7">call </span><span class="text_8">popcli </span><span class="text_7">only after the </span><span class="text_8">xchg </span><span class="text_7">that releases the lock </span><span class="text_6">(1583)</span><span class="text_7">.</span></p>
	<p class="block_150"><span class="text_7">The interaction between interrupt handlers and non-interrupt code provides a nice example why recursive locks are problematic. If xv6 used recursive locks (a second acquire on a CPU is allowed if the first acquire happened on that CPU too), then interrupt handlers could run while non-interrupt code is in a critical section. This could create havoc, since when the interrupt handler runs, invariants that the handler relies on might be temporarily violated. For example, </span><span class="text_8">ideintr </span><span class="text_6">(4202) </span><span class="text_7">assumes that the linked list with outstanding requests is well-formed. If xv6 would have used recursive locks, then </span><span class="text_8">ideintr </span><span class="text_7">might run while </span><span class="text_8">iderw </span><span class="text_7">is in the middle of manipulating the linked list, and the linked list will end up in an incorrect state.</span></p>
	<h3 class="block_17">Memory ordering</h3>
	<p class="block_14">This chapter has assumed that processors start and complete instructions in the order in which they appear in the program. Many processors, however, execute instructions out of order to achieve higher performance. If an instruction takes many cycles to complete, a processor may want to issue the instruction early so that it can overlap with other instructions and avoid processor stalls. For example, a processor may notice that in a serial sequence of instruction A and B are not dependent on each other and start instruction B before A so that it will be completed when the processor completes A. Concurrency, however, may expose this reordering to software, which lead to incorrect behavior.</p>
	<p class="block_80">For example, one might wonder what happens if <span class="text_3">release </span>just assigned 0 to <span class="text_3">lk&gt;locked</span>, instead of using <span class="text_3">xchg</span>. The answer to this question is unclear, because different generations of x86 processors make different guarantees about memory ordering. If <span class="text_3">lk-&gt;locked=0</span>, were allowed to be re-ordered say after <span class="text_3">popcli</span>, then <span class="text_3">acquire </span>might break, because to another thread interrupts would be enabled before a lock is released. To avoid relying on unclear processor specifications about memory ordering, xv6 takes no risk and uses <span class="text_3">xchg</span>, which processors must guarantee not to reorder.</p>
	<h3 class="block_17">Real world</h3>
	<p class="block_11">Concurrency primitives and parallel programming are active areas of of research, because programming with locks is still challenging. It is best to use locks as the base for higher-level constructs like synchronized queues, although xv6 does not do this. If you program with locks, it is wise to use a tool that attempts to identify race conditions, because it is easy to miss an invariant that requires a lock.</p>
	<p class="block_14">User-level programs need locks too, but in xv6 applications have one thread of execution and processes don’t share memory, and so there is no need for locks in xv6 applications.</p>
	<p class="block_14">It is possible to implement locks without atomic instructions, but it is expensive, and most operating systems use atomic instructions.</p>
	<p class="block_14">Atomic instructions are not free either when a lock is contented. If one processor has a lock cached in its local cache, and another processor must acquire the lock, then the atomic instruction to update the line that holds the lock must move the line from the one processor’s cache to the other processor’s cache, and perhaps invalidate any other copies of the cache line. Fetching a cache line from another processor’s cache can be orders of magnitude more expensive than fetching a line from a local cache.</p>
	<p class="block_14">To avoid the expenses associated with locks, many operating systems use lock-free data structures and algorithms, and try to avoid atomic operations in those algorithms. For example, it is possible to implemented a link list like the one in the beginning of the chapter that requires no locks during list searches, and one atomic instruction to insert an item in a list.</p>
	<h3 class="block_151">Exercises</h3>
	<ol class="list_">
	<li class="block_129">Remove the xchg in acquire. explain what happens when you run xv6?</li>
	<li class="block_107">Move the acquire in iderw to before sleep. is there a race? why don’t you observe itwhen booting xv6 and run stressfs? increase critical section with a dummy loop; what do you see now? explain.</li>
	<li class="block_92">Setting a bit in a buffer’s <span class="text_3">flags </span>is not an atomic operation: the processor makes a copy of <span class="text_3">flags </span>in a register, edits the register, and writes it back. Thus it is important that two processes are not writing to <span class="text_3">flags </span>at the same time. xv6 edits the <span class="text_3">B_BUSY </span>bit only while holding <span class="text_3">buflock </span>but edits the <span class="text_3">B_VALID </span>and <span class="text_3">B_WRITE </span><span class="text_2">flags without holding any locks. Why is this safe?<br class="calibre12" id="calibre_pb_8"/>
</span></li>
</ol>
	</body></html>
